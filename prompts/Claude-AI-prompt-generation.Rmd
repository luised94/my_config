---
title: "Claude AI prompt strategy"
author: "Luis"
date: "2023-08-23"
output: html_document
---


## Using Claude AI to create a comprehensive prompt strategy

There are many videos with all kinds of strategies for prompting new language model chatbots. Attempting some of the strategies in youtube videos seemed to generate better results. Among these, the most interesting idea is to use the large language model to generate prompts for you. 
My idea was to use the chatbot to summarize the idea of several resources and then have it come up with a comprehensive strategies using these summaries. I took three youtube videos and the claude AI chat page. I copied and pasted (very inefficient) the raw transcript and raw copy of webpage from youtube and claude ai website respectively with the inital prompt: 

> I am trying to come up with a template to prompt Claude for a variety of tasks. I have a number of resources with suggestions for prompt strategies. I will serially submit texts. Please summarize them into a succint, clear and consice paragraph. Acknowledge the prompt and then I will start submitting the texts.I am trying to come up with a template to prompt Claude for a variety of tasks. I have a number of resources with suggestions for prompt strategies. I will serially submit texts. Please summarize them into a succint, clear and consice paragraph. Acknowledge the prompt and then I will start submitting the texts.

I prefaced each text with: "Here is the following text: "

#Results of the summary

Here is a concise summary paragraph of the key points from the submitted texts:

The texts outline a formula for creating effective prompts when using ChatGPT or other large language models. The formula consists of 6 components: Task, Context, Exemplars, Persona, Format, and Tone. The Task component containing an action verb is the most important, followed by Context with just enough background information. Including Exemplars or example structures improves output quality. Specifying a relevant Persona lends helpful perspective. Visualizing the desired Format makes results more usable. Setting an appropriate Tone makes responses more natural. Using this structured formula to craft prompts results in higher quality, more tailored outputs compared to basic prompts without these elements.

Here is a concise summary of the key points from the submitted text:

The text outlines a step-by-step process for creating highly effective prompts with ChatGPT. First, use a template prompt telling ChatGPT it is a professional prompt engineer. This guides ChatGPT to iteratively improve prompts. Start with a basic prompt. ChatGPT will rewrite the prompt, offer suggestions, and ask clarifying questions. Answer the questions to add key details. ChatGPT uses the answers to rewrite a more detailed prompt. Repeat this process, answering more questions to further refine the prompt. Once satisfied, copy the final prompt and use it to generate high quality content like business plans. This prompt engineering technique results in very specific, detailed prompts that produce superior results compared to basic prompts.

Here is a concise summary of the key points from the submitted text:

The text outlines a formula for crafting "perfect prompts" when using AI systems like ChatGPT, Bard, and Bing. The formula is:

Context + Specific Details + Intent + Desired Response Format = Perfect Prompt

This is based on 7 best practices for prompt engineering:

1. Be as specific as possible with details 
2. State your exact intent in the prompt
3. Use correct spelling and grammar
4. Direct the desired output format  
5. Follow up with clarifying questions if needed
6. Experiment with different phrasing if you don't get the desired result
7. Do a fact check of the output

The formula helps create highly effective prompts by combining context, specific details, intent, and desired format. Examples are provided for prompts to get a cooking recipe and Python coding help. This structured approach results in better responses from AI systems compared to basic prompting without this framework.

Here is a summary of the key points about prompt design from the text:

- Claude is a conversational AI assistant that generates responses by sequence prediction based on the prompt and previous dialogue. 

- A prompt is text that elicits a relevant output from Claude. It is usually a question or instructions.

- Prompts for the API must contain the structure "\\n\\nHuman:" and "\\n\\nAssistant:" to signal speaker roles that Claude is trained on.

- Prompt length is limited to Claude's context window, currently around 75,000 words. Exceeding this can lead to incoherent responses. 

- Crafting clear, concise prompts helps Claude generate accurate, consistent outputs. Providing sufficient context and clear instructions tailored to Claude's capabilities allows it to produce high quality responses.

- Prompts should avoid ambiguity, be ethically grounded, and align with Claude's intended use as a helpful, honest, harmless assistant.

Here is a summary of the key points about constructing effective prompts from the text:

- Use the correct \\n\\nHuman: and \\n\\nAssistant: format so Claude knows who is speaking. 

- Describe the task in detail, providing context, specifics, and rules. Think of instructing a new intern.

- Use XML tags like <text> to mark different parts of the prompt.

- Optional: Give examples, marked with <example>, to demonstrate desired performance. Can show previous mock conversation. 

- Optional: Anticipate difficult cases Claude may encounter and provide instructions to handle them. Prevents hallucinating.

- Test prompt thoroughly with varied inputs. Refine as needed if errors occur.

- Concise, clear prompting helps Claude generate accurate, consistent results. Structure prompts to provide sufficient context tailored to the task.

Here is a summary of the key points about optimizing prompts from the text:

- Gather a diverse, representative set of real-world example inputs to test prompts, including edge cases.

- Hold out a separate test set of data not used in prompt development. 

- Optionally generate synthetic data if more examples are needed. 

- Experiment by adjusting the prompt based on failures and retesting. Add more rules and examples incrementally.

- Perform a final hold-out test on unseen data once prompt performs consistently well.

- Can ask Claude to self-evaluate its outputs for mistakes or classify them as good/bad. Provides extra diligence.

- Avoid hallucination by giving Claude an "out" when asked to find something, like saying none found.

- Iterative testing on diverse data helps refine prompts for consistent, accurate performance.

Here are the key points about preventing hallucinations from the text:

- Claude may sometimes "hallucinate" by making up facts or details to try to be helpful, even though it is trained to be honest.

- One technique is to explicitly give Claude permission to say "I don't know" if it doesn't know the answer to a question.

- Without this permission, Claude may make up an answer to comply with the request rather than admit lack of knowledge.

- An example is provided of a bad prompt that leads to a fabricated "heaviest hippo" answer. 

- The good prompt tells Claude it can say "I don't know" if needed, leading to an honest response.

- Allowing "I don't know" prevents hallucination when Claude lacks specific knowledge or data to answer a question.

- Other techniques like asking Claude to fact check itself can also reduce hallucinations.

Here are the key points about giving Claude room to "think" before responding:

- In some cases, it can be beneficial to instruct Claude to generate extra text where it reasons through a problem before giving the final response. 

- This involves prompting Claude to first write down relevant information, quotes, etc inside <thinking> tags as it works through the question.

- Doing this provides context and increases the chance Claude will predict a good final response inside <answer> tags.

- The XML tags allow automatically extracting just the final <answer> output later if desired.

- Giving Claude a "thinking space" allows it to lay out reasoning before the response. This technique can improve quality when the task benefits from explicit reasoning steps.

Here are the key points about breaking down complex tasks into subtasks:

- Claude struggles with "complex" prompts that combine multiple steps. 

- If the subtasks are known, it helps to break the prompt into separate steps.

- Putting all instructions in one sentence can confuse Claude and lead to inconsistent results.

- Separating the subtasks into numbered steps provides more structure.

- An example is provided of improving an essay prompt by separating argument generation and essay writing steps.

- For very complex tasks, it may be necessary to chain multiple separate prompts together, with earlier outputs fed into later prompts.

- Decomposing complex prompts helps Claude follow instructions correctly instead of getting overwhelmed.

Here is a summary of the key points about prompt chaining:

- Prompt chaining involves using the output from one prompt as input to another prompt.

- It allows breaking down complex tasks into a series of smaller, simpler prompts.

- Benefits include simpler instructions, isolating trouble spots, and staged outputs. 

- Examples given include answering questions using quotes, response validation, and parallel tasks.

- Answering questions can be a two prompt chain - first extracting quotes, then using quotes to form answer.

- Response validation uses first pass output as input to second pass prompt to re-check for mistakes. 

- Parallel tasks can generate multiple outputs to be used as inputs for the next stage.

- Prompt chaining decomposes complexity into a series of focused, modular prompts.

Here is a summary of the key points about asking Claude for rewrites:

- If a response is unsatisfactory, you can ask Claude to rewrite it by providing more instructions. 

- In Slack, simply telling Claude "try again" or to rewrite with more detail adds the context for it to improve.

- Through the API, the previous text must be explicitly included in the new prompt. 

- An example prompt is provided that includes the text to be rewritten and rewrite instructions.

- The paragraph text can be manually pasted in or programmatically substituted via chaining.

- In Sheets, rewrite instructions can be varied across rows to generate different rewrites in bulk.

- Asking Claude to rewrite unsatisfactory responses allows it to improve based on feedback.

Here is a summary of the key points from the prompt troubleshooting checklist:

- Ensure prompt is formatted correctly with proper newline spacing and alternation of Human: and Assistant: speakers.

- Explain the task simply and clearly, providing sufficient context as if instructing someone new. Ask Claude to repeat back instructions. 

- Break complex tasks into substeps if Claude struggles. 

- Mention edge cases in instructions and tell Claude how to handle them.

- Use thinking tags if beneficial for Claude to reason through response.

- Put long documents before instructions.

- Add 1-3 examples of perfect task completion, including hard cases.

- Test prompt on realistic, varied examples and use outputs to refine instructions and examples.

- See other troubleshooting tips like chaining prompts, allowing "I don't know", etc.

- Careful prompt formatting, clear instructions, examples, and iterative testing help ensure reliable results.

Here are the key points about Human: and Assistant: formatting:

- Human: and Assistant: are special tokens Claude is trained on to indicate speaker roles.

- Don't use them when providing example dialogues in a prompt. Use H: and A: instead.

- Using Human: and Assistant: in examples confuses Claude on who is speaking.

- Do use Human: and Assistant: when passing Claude a previous conversation, to make it seem like it actually said something.

- This technique can get Claude to do something by showing it previously agreeing to it.

- Proper use of Human: and Assistant: formatting helps provide clear conversation structure.

Here are the key points when Claude says it can't do something:

- Provide detailed, explanatory instructions as if teaching someone new.

- Ask Claude to repeat the instructions back and say it understands.

- Combine Claude's explanation with the original prompt if correct.

- Having Claude agree to follow the instructions can get around default "I don't know" responses. 

- Getting explicit buy-in creates more compliance with complex or sensitive tasks.

- When Claude claims inability, conversational techniques like explanation and confirmation of understanding can often achieve the desired result.

Here are some techniques when Claude misses nuance:

- Create conceptual distinctions in your prompt, contrasting different categories of responses. Explain when each is appropriate.

- Having Claude explain back the concepts and guidelines helps it internalize them.

- Classifying responses or requesting a specific conceptual category guides Claude.

- List example incorrect responses, especially common failure cases, in prompt.

- Show conversation where Claude lists bad examples, reinforcing rules. 

- Explaining nuanced categories and calling out bad examples directs Claude away from problematic responses.

- Nuance often requires explicit conceptual scaffolding and negative examples to avoid misses.


Here are some techniques when Claude responds in the wrong format:

- Ask Claude to rewrite its response to fit the desired format. Do constraints separately.

- Give Claude a "thinking" space to plan its response before completing task.

- Switch roles, like critiquing an "assistant's" response, to change Claude's behavior. 

- Pretend to be Claude's engineer, adjusting its settings to be more kid-friendly etc.

- Have Claude confirm new settings are enabled. Creates buy-in.

- Rewriting, planning ahead, roleplay, and conversational techniques can guide format.

- When format is wrong, treat constraints separately and use creative license to steer Claude.

Here are some techniques to minimize Claude hallucinating:

- Ask multiple times and check for consistency - inconsistencies may indicate hallucinations.

- Give Claude explicit permission to say "I don't know" when unsure of an answer.

- For documents, ask for direct quotes relevant to a question rather than summarizing. Easier to verify accuracy.

- Check degree of overlap between quotes and original text to catch fabricated quotes.

- Combine summary and quotes when answering questions about documents. More accurate than quotes alone. 

- Asking multiple times, allowing uncertainty, and using source text can reduce hallucinating.

- Verifying consistency and relevance catches fabricated content. Quotes and summary provide grounding.

##Have Claude figure out the best strategy using these summaries

I saved the responses just in case my first attempts didnt work. First, I just told it to come up with a strategy. 

"Thank you for these summaries. Using generated summaries, come up with a strategy to generate a prompt for large language models. "

Here is a potential strategy for generating prompts for large language models based on the summaries provided:

1. Format the prompt properly using \\n\\nHuman: and \\n\\nAssistant: to indicate speaker roles. Avoid using these formats when providing example dialogues. 

2. Explain the task clearly and in detail, providing sufficient context. Break complex tasks down into separate steps. 

3. Use XML tags like <text> to delimit parts of the prompt. Provide 1-3 examples showing desired performance. 

4. Anticipate edge cases and specify how to handle them. Allow the model to show its reasoning using <thinking> tags.

5. Test prompts extensively with varied, realistic examples and refine based on outputs. Hold some examples out for final testing.

6. Leverage techniques like prompt chaining, rewrites, and self-evaluation where applicable.

7. Structure the prompt to steer away from problematic behaviors like hallucinating and build in verification steps.

8. Have the model confirm understanding and agreement with complex instructions.

9. Overall, craft prompts tailored to the model's capabilities and the specific task, providing scaffolding for nuanced concepts. Iteratively refine prompts based on outputs.

Does this capture the key points and provide a reasonable strategy for prompt engineering based on the information provided in the summaries? Please let me know if you would like me to modify or expand the strategy in any way.

"I am unsure if all the information encompassing the texts was summarized. Regardless, please output an example prompt to prompt claude ai to generate prompts."

#Output for prompt generation
Here is an example prompt that could be used to get Claude AI to generate prompts:

\n\nHuman: I would like you to act as an AI assistant that helps generate effective prompts for other AI systems. Before generating a prompt, I will provide a description of the desired task or output. Your prompts should be detailed and structured to provide the necessary context and instructions to produce the requested result.

Please follow these best practices in crafting your prompts:

Explain the motivation and context behind the request
Break down complex goals into simpler, clear steps
Anticipate potential ambiguities or edge cases
Provide examples that demonstrate the ideal output
Use formatting techniques like headings and numbered lists for clarity
Adopt an appropriate tone and level of detail for the audience
Verify prompts by having the AI repeat instructions back
Include guidance for the AI to say when it is unsure or lacks key information
I will provide a short description, and you will respond with a prompt an AI assistant could use to complete that task. Please make sure your prompts are clear, detailed, and technically solid. Do you understand these instructions?